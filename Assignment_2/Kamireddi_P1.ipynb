{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification models to predict if an employee will leave or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SparkSession libraries.\n",
    "# Creating an instance 'logReg' for the SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('logreg').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the data from csv file into the dataframe 'data'\n",
    "data = spark.read.csv('HR_comma_sep.csv', inferSchema=True, header=True)\n",
    "# Printing the schema of the file\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the statistical summary of the data\n",
    "data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays only the features\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Vectors, VectorAssembler, Pipeline and StringIndexer libraries\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StringIndexer - A label indexer that maps a string column of labels to an ML column of label indices.\n",
    "# If the input column is numeric, we cast it to string and index the string values.\n",
    "# The indices are in [0, numLabels), ordered by label frequencies. So the most frequent label gets index 0.\n",
    "indexer = StringIndexer(inputCol='salary', outputCol='salary_in')\n",
    "# Fits a model to the input dataset with optional parameters.\n",
    "# Transforms the input dataset with optional parameters.\n",
    "indexed = indexer.fit(data).transform(data)\n",
    "indexed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VectorAssembler - A feature transformer that merges multiple columns into a vector column.\n",
    "assembler = VectorAssembler(inputCols=['satisfaction_level',\n",
    " 'last_evaluation',\n",
    " 'number_project',\n",
    " 'average_montly_hours',\n",
    " 'time_spend_company',\n",
    " 'Work_accident',\n",
    " 'promotion_last_5years',\n",
    " 'salary_in'\n",
    " ], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transform() - Transforms the input dataset with optional parameters and returns transformed dataset.\n",
    "output = assembler.transform(indexed)\n",
    "final_data=output.select('features', 'left')\n",
    "# randomSplit - Randomly splits this RDD with the provided weights and returns split RDDs in a list. \n",
    "train_churn, test_churn=final_data.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Logistic Regression libraries\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression - supports multinomial logistic (softmax) and binomial logistic regression.\n",
    "lr_churn=LogisticRegression(maxIter=30, regParam=0.0, elasticNetParam=0.0, labelCol='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit() - Fits a model to the input dataset with optional parameters and returns fitted model.\n",
    "fitted_churn_model = lr_churn.fit(train_churn)\n",
    "training_summary = fitted_churn_model.summary\n",
    "# predictions - Predictions associated with the boundaries at the same index, monotone because of isotonic regression.\n",
    "training_summary.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier - Binary Classification Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing BinaryClassificationEvaluator Libraries for evaluating the Logistic Regression model \n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate() - Evaluates the output with optional parameters and returns a metric.\n",
    "pred_and_labels = fitted_churn_model.evaluate(test_churn)\n",
    "pred_and_labels.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied the BinaryClassificationEvaluator - Evaluator for binary classification, which expects two input columns:\n",
    "# rawPrediction and label.\n",
    "churn_eval = BinaryClassificationEvaluator(rawPredictionCol='prediction', labelCol='left')\n",
    "auc = churn_eval.evaluate(pred_and_labels.predictions)\n",
    "auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing RandomForestClassifier libraries\n",
    "from pyspark.ml.classification import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data randomly into training and testing data.\n",
    "splitSeed = 5043\n",
    "train_data, test_data=output.randomSplit([0.7,0.3], splitSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied the RandomForestClassifier technique with parameters to tweak\n",
    "classifier = RandomForestClassifier(impurity=\"entropy\", numTrees=20, maxDepth=30, seed=5043, labelCol=\"left\")\n",
    "# Fits a model to the input dataset with optional parameters.\n",
    "model = classifier.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest - Multiclass Classification Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Multiclass Classification Evaluator libraries\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the input dataset with optional parameters.\n",
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"satisfaction_level\", \"left\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied the Multiclass Classification Evaluator\n",
    "data_eval = MulticlassClassificationEvaluator(labelCol='left')\n",
    "# Evaluation of the predicted values on a scale of 0 to 1\n",
    "auc1 = data_eval.evaluate(predictions)\n",
    "auc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Naive Bayes libraries\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spliting the data randomly into training and testing data.\n",
    "train_data2, test_data2=output.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied the NaiveBayes technique with parameters to tweak\n",
    "classifier = NaiveBayes(smoothing=0.2, modelType=\"multinomial\", labelCol=\"left\")\n",
    "# Fits a model to the input dataset with optional parameters.\n",
    "model = classifier.fit(train_data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes - Multiclass Classification Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Multiclass Classification Evaluator libraries\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms the input dataset with optional parameters.\n",
    "predictions = model.transform(test_data2)\n",
    "predictions.select(\"satisfaction_level\", \"left\", \"prediction\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applied the Multiclass Classification Evaluator\n",
    "data_eval = MulticlassClassificationEvaluator(labelCol='left')\n",
    "# Evaluation of the predicted values on a scale of 0 to 1\n",
    "auc1 = data_eval.evaluate(predictions)\n",
    "auc1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Among all the three classification techniques, Random Forest Classification technique gave the most accurate predicted model with approximately 0.98 accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
